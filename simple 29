
# --- Step 1: Import libraries ---
import pandas as pd
import matplotlib.pyplot as plt

# --- Step 2: Load Excel data ---
# Replace 'your_file.xlsx' with the actual filename or path
file_path = "your_file.xlsx"
df = pd.read_excel(file_path)

# --- Step 3: Inspect data ---
print(df.head())

# --- Step 4: Ensure correct data types ---
# Convert Date column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# --- Step 5: Sort by date (important for time series) ---
df = df.sort_values(by='Date')

# --- Step 6A: Plot total daily PnL (all books combined) ---
plt.figure(figsize=(12, 6))
df.groupby('Date')['Daily PnL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# --- Step 6B: Plot each book separately (optional) ---
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('Book Name'):
    plt.plot(sub_df['Date'], sub_df['Daily PnL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (with Theme Chart)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

DATA_FOLDER = "data/positions/"   # Folder containing your daily CSVs
TOP_N_TICKERS = 10                # Number of tickers to show in ticker chart (set None to show all)
TOP_N_THEMES = 10                 # Number of top themes to show in theme chart

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)
print(f"Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

df.columns = df.columns.str.lower().str.strip()

required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional', 'master_name']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df = df.dropna(subset=['date'])
df = df[df['region'].astype(str).str.upper() == 'EMEA']
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE BY BLOOMBERG TICKER
# ----------------------------

summary_tickers = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary_tickers.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary_tickers = summary_tickers[summary_tickers['bloomberg_ticker'].isin(top_tickers)]
    print(f"Showing top {len(top_tickers)} tickers by total notional.")

pivot_tickers = (
    summary_tickers
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 4: PLOT BLOOMBERG TICKER TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_tickers.plot(ax=plt.gca())
plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 5: GROUP & AGGREGATE BY THEME (LAST 4 LETTERS OF MASTER_NAME)
# ----------------------------

df['theme'] = df['master_name'].astype(str).str[-4:].str.upper()

summary_themes = (
    df.groupby(['date', 'theme'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_THEMES is not None:
    top_themes = (
        summary_themes.groupby('theme')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_THEMES)
        .index
    )
    summary_themes = summary_themes[summary_themes['theme'].isin(top_themes)]
    print(f"Showing top {len(top_themes)} themes by total notional.")

pivot_themes = (
    summary_themes
    .pivot(index='date', columns='theme', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT THEME TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_themes.plot(ax=plt.gca())
plt.title("EMEA Region — Total Basket Notional by Theme (Last 4 Letters of Basket) Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Theme", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_ticker_path = "emea_basket_notional_timeseries_by_ticker.csv"
pivot_tickers.to_csv(output_ticker_path)

output_theme_path = "emea_basket_notional_timeseries_by_theme.csv"
pivot_themes.to_csv(output_theme_path)

print(f"Saved ticker-level time series to: {output_ticker_path}")
print(f"Saved theme-level time series to: {output_theme_path}")

if error_log:
    pd.DataFrame(error_log).to_csv("error_log.csv", index=False)
    print("Error log saved to: error_log.csv")

# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (Robust Version)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        # Read CSV, skip bad lines that cause tokenizing errors
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"❌ Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)

print(f"✅ Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"⚠️ Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Normalize column names
df.columns = df.columns.str.lower().str.strip()

# Validate columns
required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

# Convert date
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing or invalid dates
df = df.dropna(subset=['date'])

# Filter EMEA region
df = df[df['region'].astype(str).str.upper() == 'EMEA']

# Drop empty or invalid notional rows
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"📊 After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL — FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]
    print(f"📈 Showing top {len(top_tickers)} tickers by total notional.")

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = (
    summary
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"💾 Aggregated time series saved to: {output_path}")

# Optional: save log of skipped files
if error_log:
    error_log_df = pd.DataFrame(error_log)
    error_log_df.to_csv("error_log.csv", index=False)
    print("🧾 Error log saved to: error_log.csv")


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES
# ----------------------------

# Find all CSV files in the folder
files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

# Load and concatenate all CSVs
df_list = []
for f in files:
    temp = pd.read_csv(f)
    df_list.append(temp)

df = pd.concat(df_list, ignore_index=True)

print(f"✅ Loaded {len(files)} files with {len(df)} total rows.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing dates
df = df.dropna(subset=['date'])

# Ensure column names are consistent (handle potential casing issues)
df.columns = df.columns.str.lower().str.strip()

# Filter only EMEA region
df = df[df['region'].str.upper() == 'EMEA']

# Check column existence
required_cols = ['date', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Column '{col}' not found in the CSV files. Found columns: {df.columns.tolist()}")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL — FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = summary.pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional').fillna(0)

# Sort by date
pivot_df = pivot_df.sort_index()

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

# Save aggregated data for further analysis
output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"📁 Aggregated time series saved to: {output_path}")