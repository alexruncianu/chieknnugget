
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Create simplified dataframe with GXC and ZSB

# Pivot daily PnL
daily_pnl = df.pivot(index='CoB', columns='BookName', values='DailyPL')[['GXC', 'ZSB']]

# Pivot cumulative PnL (starting at 0)
cumulative_pnl = df.groupby('BookName').apply(lambda x: x.set_index('CoB')['DailyPL'].cumsum())
cumulative_pnl = cumulative_pnl.unstack(level=0)[['GXC', 'ZSB']]
cumulative_pnl = cumulative_pnl - cumulative_pnl.iloc[0]  # start at 0

# Combine into a single dataframe
combined_df = pd.concat([daily_pnl.add_suffix('_DailyPL'), cumulative_pnl.add_suffix('_CumulativePL')], axis=1)

# Display the simplified dataframe
display(combined_df)




import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Display data table with Daily, Total, and Cumulative PnL
df['TotalDailyPL'] = df.groupby('CoB')['DailyPL'].transform('sum')
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()
df['CumulativePL'] = df.groupby('BookName')['CumulativePL'].apply(lambda x: x - x.iloc[0])

# Reorder columns for display
display_df = df[['CoB', 'BookName', 'DailyPL', 'TotalDailyPL', 'CumulativePL']]

# Display the table
display(display_df)



import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types (optional check)
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book} (7d avg)")
plt.title('7-Day Rolling Average PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
file_path = "your_file.csv"

# Try UTF-8 first, fallback if needed
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Clean column names (remove hidden spaces)
df.columns = df.columns.str.strip()

# Convert CoB to datetime
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')
df = df.dropna(subset=['CoB'])
df = df.sort_values(by='CoB')

# Clean DailyPL column:
# Remove spaces, commas, currency symbols, etc.
df['DailyPL'] = (
    df['DailyPL']
    .astype(str)
    .str.replace(',', '', regex=False)
    .str.replace('£', '', regex=False)
    .str.replace('$', '', regex=False)
    .str.replace('€', '', regex=False)
    .str.replace('−', '-', regex=False)  # handle unicode minus sign
    .str.replace(' ', '', regex=False)   # remove spaces
)

# Convert to numeric (coerce errors to NaN)
df['DailyPL'] = pd.to_numeric(df['DailyPL'], errors='coerce')
df = df.dropna(subset=['DailyPL'])

# Inspect cleaned data
print("Sample of cleaned data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"

# Try UTF-8 first, fall back to common Windows encoding if it fails
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')  # convert date column
df = df.dropna(subset=['CoB'])  # drop rows where date conversion failed
df = df.sort_values(by='CoB')   # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()






# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"

# Try UTF-8 first, fall back to common Windows encoding if it fails
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')  # convert date column
df = df.dropna(subset=['CoB'])  # drop rows where date conversion failed
df = df.sort_values(by='CoB')   # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()


# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'])  # convert date column
df = df.sort_values(by='CoB')          # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# --- Step 1: Import libraries ---
import pandas as pd
import matplotlib.pyplot as plt

# --- Step 2: Load Excel data ---
# Replace 'your_file.xlsx' with the actual filename or path
file_path = "your_file.xlsx"
df = pd.read_excel(file_path)

# --- Step 3: Inspect data ---
print(df.head())

# --- Step 4: Ensure correct data types ---
# Convert Date column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# --- Step 5: Sort by date (important for time series) ---
df = df.sort_values(by='Date')

# --- Step 6A: Plot total daily PnL (all books combined) ---
plt.figure(figsize=(12, 6))
df.groupby('Date')['Daily PnL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# --- Step 6B: Plot each book separately (optional) ---
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('Book Name'):
    plt.plot(sub_df['Date'], sub_df['Daily PnL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (with Theme Chart)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

DATA_FOLDER = "data/positions/"   # Folder containing your daily CSVs
TOP_N_TICKERS = 10                # Number of tickers to show in ticker chart (set None to show all)
TOP_N_THEMES = 10                 # Number of top themes to show in theme chart

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)
print(f"Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

df.columns = df.columns.str.lower().str.strip()

required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional', 'master_name']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df = df.dropna(subset=['date'])
df = df[df['region'].astype(str).str.upper() == 'EMEA']
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE BY BLOOMBERG TICKER
# ----------------------------

summary_tickers = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary_tickers.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary_tickers = summary_tickers[summary_tickers['bloomberg_ticker'].isin(top_tickers)]
    print(f"Showing top {len(top_tickers)} tickers by total notional.")

pivot_tickers = (
    summary_tickers
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 4: PLOT BLOOMBERG TICKER TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_tickers.plot(ax=plt.gca())
plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 5: GROUP & AGGREGATE BY THEME (LAST 4 LETTERS OF MASTER_NAME)
# ----------------------------

df['theme'] = df['master_name'].astype(str).str[-4:].str.upper()

summary_themes = (
    df.groupby(['date', 'theme'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_THEMES is not None:
    top_themes = (
        summary_themes.groupby('theme')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_THEMES)
        .index
    )
    summary_themes = summary_themes[summary_themes['theme'].isin(top_themes)]
    print(f"Showing top {len(top_themes)} themes by total notional.")

pivot_themes = (
    summary_themes
    .pivot(index='date', columns='theme', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT THEME TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_themes.plot(ax=plt.gca())
plt.title("EMEA Region — Total Basket Notional by Theme (Last 4 Letters of Basket) Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Theme", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_ticker_path = "emea_basket_notional_timeseries_by_ticker.csv"
pivot_tickers.to_csv(output_ticker_path)

output_theme_path = "emea_basket_notional_timeseries_by_theme.csv"
pivot_themes.to_csv(output_theme_path)

print(f"Saved ticker-level time series to: {output_ticker_path}")
print(f"Saved theme-level time series to: {output_theme_path}")

if error_log:
    pd.DataFrame(error_log).to_csv("error_log.csv", index=False)
    print("Error log saved to: error_log.csv")

# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (Robust Version)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        # Read CSV, skip bad lines that cause tokenizing errors
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"❌ Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)

print(f"✅ Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"⚠️ Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Normalize column names
df.columns = df.columns.str.lower().str.strip()

# Validate columns
required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

# Convert date
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing or invalid dates
df = df.dropna(subset=['date'])

# Filter EMEA region
df = df[df['region'].astype(str).str.upper() == 'EMEA']

# Drop empty or invalid notional rows
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"📊 After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL — FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]
    print(f"📈 Showing top {len(top_tickers)} tickers by total notional.")

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = (
    summary
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"💾 Aggregated time series saved to: {output_path}")

# Optional: save log of skipped files
if error_log:
    error_log_df = pd.DataFrame(error_log)
    error_log_df.to_csv("error_log.csv", index=False)
    print("🧾 Error log saved to: error_log.csv")


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES
# ----------------------------

# Find all CSV files in the folder
files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

# Load and concatenate all CSVs
df_list = []
for f in files:
    temp = pd.read_csv(f)
    df_list.append(temp)

df = pd.concat(df_list, ignore_index=True)

print(f"✅ Loaded {len(files)} files with {len(df)} total rows.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing dates
df = df.dropna(subset=['date'])

# Ensure column names are consistent (handle potential casing issues)
df.columns = df.columns.str.lower().str.strip()

# Filter only EMEA region
df = df[df['region'].str.upper() == 'EMEA']

# Check column existence
required_cols = ['date', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Column '{col}' not found in the CSV files. Found columns: {df.columns.tolist()}")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL — FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = summary.pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional').fillna(0)

# Sort by date
pivot_df = pivot_df.sort_index()

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region — Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

# Save aggregated data for further analysis
output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"📁 Aggregated time series saved to: {output_path}")