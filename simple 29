



import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

DATA_FOLDER = "data/positions/"   # Folder with your daily CSVs
USE_LOG_SCALE = True              # Set True for clearer visual differences
SHOW_PER_THEME_CHARTS = False     # Optional: individual charts per theme
TOP_N_TICKERS = 10                # For the ticker-level chart (optional)

# Define your themes of interest and their readable names
THEME_MAP = {
    "GRID": "Clean Energy Grid",
    "DEFE": "Defence",
    "GINF": "German Infra",
    "PHRM": "Pharma",
    "UKDM": "UK Domestic",
    "UKCS": "UK Consumer",
    "CYCL": "Cyclicals"
}

# Extract the list of themes to track
TARGET_THEMES = list(THEME_MAP.keys())

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))
if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)
print(f"Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

df.columns = df.columns.str.lower().str.strip()
required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df = df.dropna(subset=['date'])
df = df[df['region'].astype(str).str.upper() == 'EMEA']
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: ADD THEME COLUMN FROM LAST 4 CHARACTERS
# ----------------------------

df_valid_length = df[df['bloomberg_ticker'].astype(str).str.len() == 8]
df_valid_length['theme_code'] = df_valid_length['bloomberg_ticker'].astype(str).str[-4:].str.upper()

# Map theme codes to readable names
df_valid_length['theme'] = df_valid_length['theme_code'].map(THEME_MAP)

# Filter only the themes we're interested in
df_selected = df_valid_length[df_valid_length['theme_code'].isin(TARGET_THEMES)]

if df_selected.empty:
    raise ValueError("No data found for the specified themes. Check theme codes or CSV content.")

print(f"Tracking {len(TARGET_THEMES)} selected themes across {df_selected['date'].nunique()} dates.")

# ----------------------------
# STEP 4: AGGREGATE BY THEME OVER TIME
# ----------------------------

summary_themes = (
    df_selected.groupby(['date', 'theme'])['total_basket_notional']
      .sum()
      .reset_index()
)

pivot_themes = (
    summary_themes
    .pivot(index='date', columns='theme', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 5: PLOT FOCUSED THEME TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_themes.plot(ax=plt.gca(), linewidth=2)
plt.title("EMEA Region â€” Total Basket Notional by Selected Themes", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
if USE_LOG_SCALE:
    plt.yscale("log")
    plt.ylabel("Total Basket Notional (log scale)", fontsize=12)
plt.legend(title="Theme", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, which='both', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 6: OPTIONAL â€” SEPARATE CHART PER THEME
# ----------------------------

if SHOW_PER_THEME_CHARTS:
    for theme in pivot_themes.columns:
        plt.figure(figsize=(10, 5))
        plt.plot(pivot_themes.index, pivot_themes[theme], marker='o', linewidth=2)
        plt.title(f"{theme} â€” Total Basket Notional Over Time", fontsize=14)
        plt.xlabel("Date", fontsize=12)
        plt.ylabel("Total Basket Notional", fontsize=12)
        if USE_LOG_SCALE:
            plt.yscale("log")
            plt.ylabel("Total Basket Notional (log scale)", fontsize=12)
        plt.grid(True, which='both', linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS
# ----------------------------

pivot_themes.to_csv("emea_selected_theme_timeseries.csv")

if error_log:
    pd.DataFrame(error_log).to_csv("error_log.csv", index=False)

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

DATA_FOLDER = "data/positions/"   # Folder containing your daily CSVs
TOP_N_TICKERS = 10                # Number of tickers to show in ticker chart (set None to show all)
TOP_N_THEMES = 10                 # Number of top themes to show in theme chart

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)
print(f"Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

df.columns = df.columns.str.lower().str.strip()

required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df = df.dropna(subset=['date'])
df = df[df['region'].astype(str).str.upper() == 'EMEA']
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE BY BLOOMBERG TICKER
# ----------------------------

summary_tickers = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary_tickers.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary_tickers = summary_tickers[summary_tickers['bloomberg_ticker'].isin(top_tickers)]
    print(f"Showing top {len(top_tickers)} tickers by total notional.")

pivot_tickers = (
    summary_tickers
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 4: PLOT BLOOMBERG TICKER TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_tickers.plot(ax=plt.gca())
plt.title("EMEA Region â€” Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 5: THEME DERIVATION FROM LAST 4 CHARACTERS
# ----------------------------

# Only take tickers of length 8
df_valid_length = df[df['bloomberg_ticker'].astype(str).str.len() == 8]

# Extract last 4 characters as theme
df_valid_length['theme'] = df_valid_length['bloomberg_ticker'].astype(str).str[-4:].str.upper()

# Group by date and theme
summary_themes = (
    df_valid_length.groupby(['date', 'theme'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_THEMES is not None:
    top_themes = (
        summary_themes.groupby('theme')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_THEMES)
        .index
    )
    summary_themes = summary_themes[summary_themes['theme'].isin(top_themes)]
    print(f"Showing top {len(top_themes)} themes by total notional (last 4 chars of 8-char tickers).")

pivot_themes = (
    summary_themes
    .pivot(index='date', columns='theme', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT THEME TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_themes.plot(ax=plt.gca())
plt.title("EMEA Region â€” Total Basket Notional by Theme (Last 4 Letters of 8-char Tickers)", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Theme", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS
# ----------------------------

pivot_tickers.to_csv("emea_basket_notional_timeseries_by_ticker.csv")
pivot_themes.to_csv("emea_basket_notional_timeseries_by_theme_last4.csv")

if error_log:
    pd.DataFrame(error_log).to_csv("error_log.csv", index=False)



import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Clean and sort
df.columns = df.columns.str.strip()
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Pivot daily data and compute cumulative
daily_pnl = df.pivot(index='CoB', columns='BookName', values='DailyPL')

# Handle missing books
for col in ['GXC', 'ZSB']:
    if col not in daily_pnl.columns:
        daily_pnl[col] = 0

daily_pnl = daily_pnl[['GXC', 'ZSB']]

# Compute cumulative (running total)
cumulative_pnl = daily_pnl.cumsum()

# Compute total cumulative across books
cumulative_pnl['Total'] = cumulative_pnl['GXC'] + cumulative_pnl['ZSB']

# Normalized cumulative (to compare performance shape)
normalized_pnl = cumulative_pnl / cumulative_pnl.iloc[-1].replace(0, 1)

# 4. Plot raw cumulative
plt.figure(figsize=(12,6))
for col in ['GXC', 'ZSB', 'Total']:
    plt.plot(cumulative_pnl.index, cumulative_pnl[col], linewidth=2, label=f"{col} Cumulative")
plt.title('Cumulative PnL Over Time (Running Total)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 5. Plot normalized cumulative
plt.figure(figsize=(12,6))
for col in ['GXC', 'ZSB']:
    plt.plot(normalized_pnl.index, normalized_pnl[col], linewidth=2, label=f"{col} Normalized")
plt.title('Normalized Cumulative PnL (Relative Performance)')
plt.xlabel('Date (CoB)')
plt.ylabel('Normalized Value (Rebased)')
plt.legend()
plt.grid(True)
plt.show()

# 6. Combine daily and cumulative into a table
combined_df = pd.concat([
    daily_pnl.add_suffix('_DailyPL'),
    cumulative_pnl.add_suffix('_CumulativePL')
], axis=1)

# Add total row
total_row = pd.DataFrame({
    'GXC_DailyPL': [daily_pnl['GXC'].sum()],
    'ZSB_DailyPL': [daily_pnl['ZSB'].sum()],
    'Total_DailyPL': [daily_pnl['GXC'].sum() + daily_pnl['ZSB'].sum()],
    'GXC_CumulativePL': [cumulative_pnl['GXC'].iloc[-1]],
    'ZSB_CumulativePL': [cumulative_pnl['ZSB'].iloc[-1]],
    'Total_CumulativePL': [cumulative_pnl['Total'].iloc[-1]]
}, index=['Total'])

final_df = pd.concat([combined_df, total_row])

# Display final table
display(final_df)




import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df.columns = df.columns.str.strip()
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Simplified table with raw and cumulative PnL

# Pivot daily PnL
daily_pnl = df.pivot(index='CoB', columns='BookName', values='DailyPL')

# Ensure GXC and ZSB exist
for col in ['GXC','ZSB']:
    if col not in daily_pnl.columns:
        daily_pnl[col] = 0  # fill missing columns with 0

daily_pnl = daily_pnl[['GXC','ZSB']]

# Compute cumulative PnL per book (start at 0)
cumulative_pnl = daily_pnl.cumsum()
cumulative_pnl = cumulative_pnl - cumulative_pnl.iloc[0]

# Compute cumulative total across both books
cumulative_total = cumulative_pnl.sum(axis=1)

# Combine into a single dataframe
combined_df = pd.concat([
    daily_pnl.add_suffix('_DailyPL'),
    cumulative_pnl.add_suffix('_CumulativePL'),
], axis=1)

# Add total cumulative column
combined_df['Total_CumulativePL'] = cumulative_total

# Add a total row
total_row = pd.DataFrame({
    'GXC_DailyPL': [daily_pnl['GXC'].sum()],
    'ZSB_DailyPL': [daily_pnl['ZSB'].sum()],
    'GXC_CumulativePL': [cumulative_pnl['GXC'].iloc[-1]],
    'ZSB_CumulativePL': [cumulative_pnl['ZSB'].iloc[-1]],
    'Total_CumulativePL': [cumulative_total.iloc[-1]]
}, index=['Total'])

# Append total row
final_df = pd.concat([combined_df, total_row])

# Display
display(final_df)



import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df.columns = df.columns.str.strip()  # remove any whitespace
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Create simplified dataframe with GXC and ZSB

# Pivot daily PnL
daily_pnl = df.pivot(index='CoB', columns='BookName', values='DailyPL')[['GXC', 'ZSB']]

# Pivot cumulative PnL (starting at 0)
cumulative_pnl = df.groupby('BookName').apply(lambda x: x.set_index('CoB')['DailyPL'].cumsum())
cumulative_pnl = cumulative_pnl.unstack(level=0)[['GXC', 'ZSB']]
cumulative_pnl = cumulative_pnl - cumulative_pnl.iloc[0]  # start at 0

# Combine into a single dataframe
combined_df = pd.concat([daily_pnl.add_suffix('_DailyPL'), cumulative_pnl.add_suffix('_CumulativePL')], axis=1)

# 5. Add total PnL for each book as a summary row
total_row = pd.DataFrame({
    'GXC_DailyPL': [daily_pnl['GXC'].sum()],
    'ZSB_DailyPL': [daily_pnl['ZSB'].sum()],
    'GXC_CumulativePL': [cumulative_pnl['GXC'].iloc[-1]],
    'ZSB_CumulativePL': [cumulative_pnl['ZSB'].iloc[-1]],
}, index=['Total'])

# Append total row to dataframe
final_df = pd.concat([combined_df, total_row])

# Display the simplified dataframe with totals
display(final_df)

import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Create simplified dataframe with GXC and ZSB

# Pivot daily PnL
daily_pnl = df.pivot(index='CoB', columns='BookName', values='DailyPL')[['GXC', 'ZSB']]

# Pivot cumulative PnL (starting at 0)
cumulative_pnl = df.groupby('BookName').apply(lambda x: x.set_index('CoB')['DailyPL'].cumsum())
cumulative_pnl = cumulative_pnl.unstack(level=0)[['GXC', 'ZSB']]
cumulative_pnl = cumulative_pnl - cumulative_pnl.iloc[0]  # start at 0

# Combine into a single dataframe
combined_df = pd.concat([daily_pnl.add_suffix('_DailyPL'), cumulative_pnl.add_suffix('_CumulativePL')], axis=1)

# Display the simplified dataframe
display(combined_df)




import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Display data table with Daily, Total, and Cumulative PnL
df['TotalDailyPL'] = df.groupby('CoB')['DailyPL'].transform('sum')
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()
df['CumulativePL'] = df.groupby('BookName')['CumulativePL'].apply(lambda x: x - x.iloc[0])

# Reorder columns for display
display_df = df[['CoB', 'BookName', 'DailyPL', 'TotalDailyPL', 'CumulativePL']]

# Display the table
display(display_df)



import pandas as pd
import matplotlib.pyplot as plt

# Load CSV
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Ensure correct types (optional check)
df['CoB'] = pd.to_datetime(df['CoB'], dayfirst=True)
df = df.sort_values(by='CoB')

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12,6))
total_daily = df.groupby('CoB')['DailyPL'].sum()
plt.plot(total_daily.index, total_daily.values, marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book)
plt.title('Daily PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book} (7d avg)")
plt.title('7-Day Rolling Average PnL by Book')
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book (start at 0)
plt.figure(figsize=(12,6))
for book, sub_df in df.groupby('BookName'):
    cumulative = sub_df['DailyPL'].cumsum()
    cumulative = cumulative - cumulative.iloc[0]  # start at 0
    plt.plot(sub_df['CoB'], cumulative, linewidth=2, label=f"{book} (Cumulative)")
plt.title('Cumulative PnL by Book (Start at 0)')
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
file_path = "your_file.csv"

# Try UTF-8 first, fallback if needed
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Clean column names (remove hidden spaces)
df.columns = df.columns.str.strip()

# Convert CoB to datetime
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')
df = df.dropna(subset=['CoB'])
df = df.sort_values(by='CoB')

# Clean DailyPL column:
# Remove spaces, commas, currency symbols, etc.
df['DailyPL'] = (
    df['DailyPL']
    .astype(str)
    .str.replace(',', '', regex=False)
    .str.replace('Â£', '', regex=False)
    .str.replace('$', '', regex=False)
    .str.replace('â‚¬', '', regex=False)
    .str.replace('âˆ’', '-', regex=False)  # handle unicode minus sign
    .str.replace(' ', '', regex=False)   # remove spaces
)

# Convert to numeric (coerce errors to NaN)
df['DailyPL'] = pd.to_numeric(df['DailyPL'], errors='coerce')
df = df.dropna(subset=['DailyPL'])

# Inspect cleaned data
print("Sample of cleaned data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"

# Try UTF-8 first, fall back to common Windows encoding if it fails
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')  # convert date column
df = df.dropna(subset=['CoB'])  # drop rows where date conversion failed
df = df.sort_values(by='CoB')   # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()






# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"

# Try UTF-8 first, fall back to common Windows encoding if it fails
try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'], errors='coerce')  # convert date column
df = df.dropna(subset=['CoB'])  # drop rows where date conversion failed
df = df.sort_values(by='CoB')   # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()


# Import libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load CSV data
# Replace 'your_file.csv' with your actual file name or path
file_path = "your_file.csv"
df = pd.read_csv(file_path)

# Data cleaning
df['CoB'] = pd.to_datetime(df['CoB'])  # convert date column
df = df.sort_values(by='CoB')          # sort by date

# Inspect data
print("Sample of data:")
print(df.head(), "\n")

# 1. Total Daily PnL (all books combined)
plt.figure(figsize=(12, 6))
df.groupby('CoB')['DailyPL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# 2. Daily PnL by Book
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['DailyPL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()

# 3. 7-Day Rolling Average per Book
df['Rolling7d'] = df.groupby('BookName')['DailyPL'].transform(lambda x: x.rolling(7).mean())

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['Rolling7d'], linewidth=2, label=f"{book_name} (7d avg)")

plt.title('7-Day Rolling Average PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('7-Day Average PnL')
plt.legend()
plt.grid(True)
plt.show()

# 4. Cumulative PnL per Book
df['CumulativePL'] = df.groupby('BookName')['DailyPL'].cumsum()

plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('BookName'):
    plt.plot(sub_df['CoB'], sub_df['CumulativePL'], linewidth=2, label=f"{book_name} (Cumulative)")

plt.title('Cumulative PnL by Book', fontsize=14)
plt.xlabel('Date (CoB)')
plt.ylabel('Cumulative PnL')
plt.legend()
plt.grid(True)
plt.show()



# --- Step 1: Import libraries ---
import pandas as pd
import matplotlib.pyplot as plt

# --- Step 2: Load Excel data ---
# Replace 'your_file.xlsx' with the actual filename or path
file_path = "your_file.xlsx"
df = pd.read_excel(file_path)

# --- Step 3: Inspect data ---
print(df.head())

# --- Step 4: Ensure correct data types ---
# Convert Date column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# --- Step 5: Sort by date (important for time series) ---
df = df.sort_values(by='Date')

# --- Step 6A: Plot total daily PnL (all books combined) ---
plt.figure(figsize=(12, 6))
df.groupby('Date')['Daily PnL'].sum().plot(marker='o', linewidth=2)
plt.title('Total Daily PnL Over Time', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.grid(True)
plt.show()

# --- Step 6B: Plot each book separately (optional) ---
plt.figure(figsize=(12, 6))
for book_name, sub_df in df.groupby('Book Name'):
    plt.plot(sub_df['Date'], sub_df['Daily PnL'], marker='o', label=book_name)

plt.title('Daily PnL by Book', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Daily PnL')
plt.legend()
plt.grid(True)
plt.show()


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (with Theme Chart)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

DATA_FOLDER = "data/positions/"   # Folder containing your daily CSVs
TOP_N_TICKERS = 10                # Number of tickers to show in ticker chart (set None to show all)
TOP_N_THEMES = 10                 # Number of top themes to show in theme chart

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)
print(f"Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

df.columns = df.columns.str.lower().str.strip()

required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional', 'master_name']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df = df.dropna(subset=['date'])
df = df[df['region'].astype(str).str.upper() == 'EMEA']
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE BY BLOOMBERG TICKER
# ----------------------------

summary_tickers = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary_tickers.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary_tickers = summary_tickers[summary_tickers['bloomberg_ticker'].isin(top_tickers)]
    print(f"Showing top {len(top_tickers)} tickers by total notional.")

pivot_tickers = (
    summary_tickers
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 4: PLOT BLOOMBERG TICKER TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_tickers.plot(ax=plt.gca())
plt.title("EMEA Region â€” Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 5: GROUP & AGGREGATE BY THEME (LAST 4 LETTERS OF MASTER_NAME)
# ----------------------------

df['theme'] = df['master_name'].astype(str).str[-4:].str.upper()

summary_themes = (
    df.groupby(['date', 'theme'])['total_basket_notional']
      .sum()
      .reset_index()
)

if TOP_N_THEMES is not None:
    top_themes = (
        summary_themes.groupby('theme')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_THEMES)
        .index
    )
    summary_themes = summary_themes[summary_themes['theme'].isin(top_themes)]
    print(f"Showing top {len(top_themes)} themes by total notional.")

pivot_themes = (
    summary_themes
    .pivot(index='date', columns='theme', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT THEME TIME SERIES
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_themes.plot(ax=plt.gca())
plt.title("EMEA Region â€” Total Basket Notional by Theme (Last 4 Letters of Basket) Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Theme", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_ticker_path = "emea_basket_notional_timeseries_by_ticker.csv"
pivot_tickers.to_csv(output_ticker_path)

output_theme_path = "emea_basket_notional_timeseries_by_theme.csv"
pivot_themes.to_csv(output_theme_path)

print(f"Saved ticker-level time series to: {output_ticker_path}")
print(f"Saved theme-level time series to: {output_theme_path}")

if error_log:
    pd.DataFrame(error_log).to_csv("error_log.csv", index=False)
    print("Error log saved to: error_log.csv")

# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis (Robust Version)
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES (ROBUST)
# ----------------------------

files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

df_list = []
error_log = []

for f in files:
    try:
        # Read CSV, skip bad lines that cause tokenizing errors
        temp = pd.read_csv(f, on_bad_lines='skip', engine='python')
        temp['source_file'] = os.path.basename(f)
        df_list.append(temp)
    except Exception as e:
        print(f"âŒ Error reading {f}: {e}")
        error_log.append({"file": f, "error": str(e)})

if not df_list:
    raise ValueError("No valid CSVs were read successfully. Check data folder and file formats.")

df = pd.concat(df_list, ignore_index=True)

print(f"âœ… Loaded {len(files)} files with {len(df)} total rows after cleaning.")
if error_log:
    print(f"âš ï¸ Skipped {len(error_log)} file(s) due to read errors.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Normalize column names
df.columns = df.columns.str.lower().str.strip()

# Validate columns
required_cols = ['date', 'region', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column '{col}' in CSV files. Found columns: {df.columns.tolist()}")

# Convert date
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing or invalid dates
df = df.dropna(subset=['date'])

# Filter EMEA region
df = df[df['region'].astype(str).str.upper() == 'EMEA']

# Drop empty or invalid notional rows
df = df.dropna(subset=['total_basket_notional'])
df['total_basket_notional'] = pd.to_numeric(df['total_basket_notional'], errors='coerce')
df = df.dropna(subset=['total_basket_notional'])

print(f"ðŸ“Š After filtering: {len(df)} valid EMEA rows remain.")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL â€” FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]
    print(f"ðŸ“ˆ Showing top {len(top_tickers)} tickers by total notional.")

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = (
    summary
    .pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional')
    .fillna(0)
    .sort_index()
)

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region â€” Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"ðŸ’¾ Aggregated time series saved to: {output_path}")

# Optional: save log of skipped files
if error_log:
    error_log_df = pd.DataFrame(error_log)
    error_log_df.to_csv("error_log.csv", index=False)
    print("ðŸ§¾ Error log saved to: error_log.csv")


# -------------------------------------------------------
# EMEA Basket Notional Time Series Analysis
# -------------------------------------------------------

import pandas as pd
import glob
import matplotlib.pyplot as plt
import os

# ----------------------------
# CONFIGURATION
# ----------------------------

# Folder containing your daily CSVs
DATA_FOLDER = "data/positions/"   # <-- Change to your folder path
TOP_N_TICKERS = 10                # Number of tickers to show in chart (set None to show all)

# ----------------------------
# STEP 1: LOAD AND COMBINE CSV FILES
# ----------------------------

# Find all CSV files in the folder
files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))

if not files:
    raise FileNotFoundError(f"No CSV files found in folder: {DATA_FOLDER}")

# Load and concatenate all CSVs
df_list = []
for f in files:
    temp = pd.read_csv(f)
    df_list.append(temp)

df = pd.concat(df_list, ignore_index=True)

print(f"âœ… Loaded {len(files)} files with {len(df)} total rows.")

# ----------------------------
# STEP 2: CLEAN & FILTER DATA
# ----------------------------

# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Drop rows with missing dates
df = df.dropna(subset=['date'])

# Ensure column names are consistent (handle potential casing issues)
df.columns = df.columns.str.lower().str.strip()

# Filter only EMEA region
df = df[df['region'].str.upper() == 'EMEA']

# Check column existence
required_cols = ['date', 'bloomberg_ticker', 'total_basket_notional']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Column '{col}' not found in the CSV files. Found columns: {df.columns.tolist()}")

# ----------------------------
# STEP 3: GROUP & AGGREGATE
# ----------------------------

summary = (
    df.groupby(['date', 'bloomberg_ticker'])['total_basket_notional']
      .sum()
      .reset_index()
)

# ----------------------------
# STEP 4: OPTIONAL â€” FILTER TOP N TICKERS BY TOTAL NOTIONAL
# ----------------------------

if TOP_N_TICKERS is not None:
    top_tickers = (
        summary.groupby('bloomberg_ticker')['total_basket_notional']
        .sum()
        .nlargest(TOP_N_TICKERS)
        .index
    )
    summary = summary[summary['bloomberg_ticker'].isin(top_tickers)]

# ----------------------------
# STEP 5: PIVOT FOR TIME SERIES VIEW
# ----------------------------

pivot_df = summary.pivot(index='date', columns='bloomberg_ticker', values='total_basket_notional').fillna(0)

# Sort by date
pivot_df = pivot_df.sort_index()

# ----------------------------
# STEP 6: PLOT RESULTS
# ----------------------------

plt.figure(figsize=(12, 6))
pivot_df.plot(ax=plt.gca())

plt.title("EMEA Region â€” Total Basket Notional by Bloomberg Ticker Over Time", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Total Basket Notional", fontsize=12)
plt.legend(title="Bloomberg Ticker", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# STEP 7: EXPORT RESULTS (Optional)
# ----------------------------

# Save aggregated data for further analysis
output_path = "emea_basket_notional_timeseries.csv"
pivot_df.to_csv(output_path)
print(f"ðŸ“ Aggregated time series saved to: {output_path}")