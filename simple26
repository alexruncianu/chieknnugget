import pandas as pd
import matplotlib.pyplot as plt

# -------------------
# Load data
# -------------------
df = pd.read_csv("your_file.csv")

# -------------------
# Identify columns
# -------------------
meta_cols = df.columns[:8].tolist()          # first 8 metadata columns
price_cols = df.columns[8:].tolist()         # from Unnamed:8 onwards (prices)

# -------------------
# Normalize to returns relative to t0 (add date price)
# -------------------
df_perf = df.copy()
P0 = df[price_cols[0]]   # price at add date (t0)

for c in price_cols:
    df_perf[c] = (df[c] / P0) - 1

# -------------------
# Fixed horizon analysis (approx 21 trading days per month)
# -------------------
months_map = {
    "1m": 21,
    "2m": 42,
    "3m": 63,
    "4m": 84,
    "5m": 105,
    "6m": 126
}

results = []

for label, day in months_map.items():
    # price_cols[0] is t0, so day offset = price_cols[day]
    if day < len(price_cols):  
        col_name = price_cols[day]  
        tmp = df_perf[[meta_cols[1], col_name]].copy()  # ticker + return
        tmp.rename(columns={col_name: "return"}, inplace=True)
        tmp["horizon"] = label
        results.append(tmp)

perf_long = pd.concat(results)

# Mean return per horizon
mean_perf = perf_long.groupby("horizon")["return"].mean()

# -------------------
# Full average performance curve
# -------------------
avg_curve = df_perf[price_cols].mean(axis=0)

# -------------------
# Plotting
# -------------------

# 1. Snapshot mean returns bar chart
plt.figure(figsize=(8,5))
mean_perf.plot(kind="bar")
plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Average Return")
plt.title("Average Return at Fixed Horizons")
plt.show()

# 2. Distribution boxplots
plt.figure(figsize=(8,5))
perf_long.boxplot(by="horizon", column="return", grid=False)
plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Return")
plt.title("Return Distribution by Horizon")
plt.suptitle("")  # remove default pandas title
plt.show()

# 3. Full performance curve (average cumulative return path)
plt.figure(figsize=(10,6))
avg_curve.plot()
plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Average Return")
plt.xlabel("Days Since Add Date (t0)")
plt.title("Average Performance Curve Across All Names")
plt.show()


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# -------------------
# Load data
# -------------------
df = pd.read_csv("your_file.csv")

# -------------------
# Identify columns
# -------------------
bbg_col = df.columns[6]   # bbg_ticker
date_col = df.columns[7]  # add_date
price_cols = df.columns[8:].tolist()

# -------------------
# Normalize prices into returns
# -------------------
df_perf = df.copy()
P0 = df[price_cols[0]]  # price at t0 (add date)

for c in price_cols:
    df_perf[c] = (df[c] / P0) - 1

# -------------------
# Horizon mapping (approx 21 trading days ~ 1 month)
# -------------------
months_map = {
    "1m": 21,
    "2m": 42,
    "3m": 63,
    "4m": 84,
    "5m": 105,
    "6m": 126
}

results = []

for label, day in months_map.items():
    if day < len(price_cols):  # only if horizon exists
        col_name = price_cols[day]
        tmp = df_perf[[bbg_col, date_col, col_name]].copy()
        tmp.rename(columns={col_name: "return"}, inplace=True)
        tmp["horizon"] = label
        results.append(tmp)

perf_long = pd.concat(results)

# -------------------
# Average performance curve
# -------------------
avg_curve = df_perf[price_cols].mean(axis=0)
day_nums = list(range(len(price_cols)))  # 0,1,2,...
avg_curve.index = day_nums

plt.figure(figsize=(10,6))
avg_curve.plot()
plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Average Return")
plt.xlabel("Days Since Add Date (t0)")
plt.title("Average Performance Curve Across All Names")
plt.show()

# -------------------
# Boxplot with labeled outliers
# -------------------
plt.figure(figsize=(10,6))
sns.boxplot(x="horizon", y="return", data=perf_long, showfliers=True)
sns.stripplot(x="horizon", y="return", data=perf_long, color="black", size=3, alpha=0.5)

# Label outliers (top & bottom 3 per horizon)
for horizon in perf_long["horizon"].unique():
    sub = perf_long[perf_long["horizon"] == horizon]
    top = sub.nlargest(3, "return")
    bottom = sub.nsmallest(3, "return")
    extremes = pd.concat([top, bottom])
    x_pos = list(perf_long["horizon"].unique()).tolist().index(horizon)
    for _, row in extremes.iterrows():
        plt.text(
            x=x_pos,
            y=row["return"],
            s=row[bbg_col],
            fontsize=8,
            ha="center",
            va="bottom" if row["return"] > 0 else "top"
        )

plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Return")
plt.title("Return Distribution by Horizon (with Outliers Labeled)")
plt.show()

# -------------------
# Stacked plot of all tickers' curves
# -------------------
plt.figure(figsize=(12,7))

for _, row in df_perf.iterrows():
    returns = row[price_cols].values
    returns = (returns / returns[0]) - 1  # normalize
    plt.plot(day_nums, returns, alpha=0.3, linewidth=1, color="gray")

# Overlay average curve
plt.plot(day_nums, avg_curve, color="red", linewidth=2, label="Average")

plt.axhline(0, color="black", linestyle="--", linewidth=1)
plt.ylabel("Return")
plt.xlabel("Days Since Add Date (t0)")
plt.title("All Tickers Performance Curves (Stacked)")
plt.legend()
plt.show()

Fund,Ticker/ISIN,Underlying Index,AuM
Xtrackers MSCI World UCITS ETF 1C,IE00BJ0KDQ92,MSCI World,€20.63B
Xtrackers S&P 500 UCITS ETF 4C,IE000Z9SJA06,S&P 500,€1.53B
Xtrackers Artificial Intelligence & Big Data UCITS ETF 1C,IE00BGV5VN51,Nasdaq Global AI & Big Data Index,€5.50B
Xtrackers II EUR Overnight Rate Swap UCITS ETF 1C,LU0290358497,EUR Overnight Rate Swap Index,€18.37M
Xtrackers DAX UCITS ETF 1C Core Direct,XDAX,DAX,€6.48B
Xtrackers Euro Stoxx 50 UCITS ETF 1D Core,LU0274211217,EURO STOXX 50,€9.94B
Xtrackers Artificial Intelligence & Big Data ETF (US),XAIX,Nasdaq Global AI & Big Data Index,Part of $21B suite
Xtrackers USD High Yield BB-B ex Financials ETF,HYLB,ICE BofA BB-B Non-Financials HY Index,$3.53B
Xtrackers US National Critical Technologies ETF,CRTC,Solactive Whitney US Critical Technologies Index,N/A
Xtrackers USA Net Zero Pathway Paris Aligned UCITS ETF 1C ESG,N/A,Solactive-ISS ESG USA Net Zero Pathway Index,N/A
Xtrackers Europe Net Zero Pathway Paris Aligned UCITS ETF 1C ESG,N/A,Solactive-ISS ESG Europe Net Zero Pathway Index,N/A
Xtrackers Japan Net Zero Pathway Paris Aligned UCITS ETF 1C ESG,N/A,Solactive-ISS ESG Japan Net Zero Pathway Index,N/A
Xtrackers Emerging Markets Net Zero Pathway Paris Aligned UCITS ETF 1C ESG,N/A,Solactive-ISS ESG EM Net Zero Pathway Index,N/A
Xtrackers MSCI China A ESG Screened Swap UCITS ETF 1C,LU2469465822,MSCI China A Inclusion Select ESG Screened Index,€5.13M
Xtrackers CSI300 Swap UCITS ETF 1C,LU0779800910,CSI 300 Swap Index,€2.05B
Xtrackers Nikkei 225 UCITS ETF 1D,XDJP,Nikkei 225,€1.60B
Xtrackers MSCI China UCITS ETF 1C,N/A,MSCI China,€1.88B


import pandas as pd
import matplotlib.pyplot as plt

# === Load your CSV ===
df = pd.read_csv("your_file.csv")

# Expected columns: ['side', 'quantity', 'bbg_ticker', 'add_date', price columns...]
price_cols = df.columns[4:]  # first 4 cols are meta, rest are Unnamed:8, Unnamed:9, ...

# Compute returns relative to trade date
returns = (df[price_cols].T / df[price_cols].iloc[:,0].values).T - 1
returns["bbg_ticker"] = df["bbg_ticker"]
returns["add_date"] = pd.to_datetime(df["add_date"])
returns["side"] = df["side"].str.lower()
returns["quantity"] = df["quantity"]

# Map side → +1 (long), -1 (short)
returns["weight"] = returns["quantity"] * returns["side"].map({"long": 1, "short": -1})

# === Group by trade date ===
portfolio_curves = {}

for trade_date, group in returns.groupby("add_date"):
    # Weighted average across tickers traded that day
    weighted = (group[price_cols].T * group["weight"].values).T
    portfolio_curve = weighted.sum(axis=0) / group["quantity"].sum()
    portfolio_curves[trade_date] = portfolio_curve

# Convert to DataFrame
portfolio_df = pd.DataFrame(portfolio_curves)

# Average performance across all trade dates
average_curve = portfolio_df.mean(axis=1)

# === Relabel X-axis as months (1m, 2m, …) ===
days = range(len(price_cols))
months = [f"{i}m" for i in range(1,7)]
month_positions = [21*i for i in range(1,7)]  # ~21 trading days = 1m

# === Plot portfolio curves ===
plt.figure(figsize=(12,7))

# Plot each trade date curve
for trade_date in portfolio_df.columns:
    plt.plot(days, portfolio_df[trade_date].values, alpha=0.4, label=str(trade_date.date()))

# Plot average curve
plt.plot(days, average_curve.values, color="black", linewidth=2, label="Average")

plt.axhline(0, color="black", linewidth=0.8)
plt.xticks(month_positions, months)
plt.xlabel("Time since trade date")
plt.ylabel("Performance vs. trade date (%)")
plt.title("Portfolio Performance by Trade Date")
plt.legend(loc="best", fontsize=8)
plt.grid(True)
plt.show()



---


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ---------- load ----------
df = pd.read_csv("your_file.csv")   # <-- change filename if needed

# ---------- find core columns (case-insensitive) ----------
cols_lower = {c.lower(): c for c in df.columns}

def find_col(names):
    for n in names:
        if n.lower() in cols_lower:
            return cols_lower[n.lower()]
    return None

side_col   = find_col(['side'])
qty_col    = find_col(['quantity','qty','size'])
ticker_col = find_col(['bbg_ticker','ticker','symbol'])
date_col   = find_col(['add_date','trade_date','date'])

if not all([side_col, qty_col, ticker_col, date_col]):
    missing = [n for n,c in [('side',side_col),('quantity',qty_col),('bbg_ticker',ticker_col),('add_date',date_col)] if c is None]
    raise ValueError(f"Could not find required columns in CSV: {missing}. Column names are case-insensitive; adapt names or rename columns.")

# ---------- identify price columns (everything else) ----------
meta_cols = {side_col, qty_col, ticker_col, date_col}
price_cols = [c for c in df.columns if c not in meta_cols]
if len(price_cols) == 0:
    raise ValueError("No price columns found. Price columns should be all columns after the meta columns.")

# ---------- prepare numeric price matrix ----------
prices = df[price_cols].apply(pd.to_numeric, errors='coerce').to_numpy(dtype=float)   # shape (n_rows, n_days)
n_days = prices.shape[1]
day_idx = np.arange(n_days)   # 0,1,2,...

# ---------- compute row-wise returns relative to t0 (first price column) ----------
P0 = prices[:, 0].astype(float)
valid = np.isfinite(P0) & (P0 != 0)
returns = np.full_like(prices, np.nan, dtype=float)
returns[valid, :] = prices[valid, :] / P0[valid, None] - 1.0

# ---------- meta dataframe ----------
meta = pd.DataFrame({
    'side_raw': df[side_col].astype(str),
    'quantity': pd.to_numeric(df[qty_col], errors='coerce').fillna(1.0),
    'ticker': df[ticker_col].astype(str),
    'trade_date': pd.to_datetime(df[date_col], errors='coerce')
})

# drop rows with invalid trade_date
meta = meta.reset_index(drop=False)  # keep original row index in column 'index'
meta.rename(columns={'index':'orig_index'}, inplace=True)

# ---------- map sides Buy/Sell to +1/-1 ----------
meta['side_norm'] = meta['side_raw'].str.strip().str.lower().map({'buy': 1, 'sell': -1})
# Any unmapped side -> raise warning and drop those rows
unmapped = meta[meta['side_norm'].isna()]
if not unmapped.empty:
    print("Warning: some 'side' values were not 'Buy' or 'Sell' (case-insensitive). These rows will be dropped:")
    print(unmapped[['orig_index','side_raw']].head())
    meta = meta[meta['side_norm'].notna()]

# build signed weights = quantity * sign
meta['signed_weight'] = meta['quantity'] * meta['side_norm']

# ---------- group by trade_date and compute portfolio curve per date ----------
portfolio_gross = {}   # gross-normalized (divide by sum abs weights present that day)
portfolio_net   = {}   # net-normalized (divide by sum signed weights) when possible

# Use the original row numbers to pick rows from returns matrix
for trade_date, group in meta.groupby('trade_date', sort=True):
    idxs = group['orig_index'].to_numpy(dtype=int)   # indices into returns matrix
    group_returns = returns[idxs, :]                 # shape (n_group, n_days)
    group_weights = group['signed_weight'].to_numpy(dtype=float)  # length n_group

    # skip groups with no valid returns (all NaN)
    if np.isnan(group_returns).all():
        continue

    # For each day compute weighted sum ignoring NaNs:
    # numerator_day = sum_i ( weight_i * return_{i,day} ) where return not NaN
    # denom_gross_day = sum_i ( |weight_i| ) where return not NaN
    mask_valid = ~np.isnan(group_returns)   # True where a given ticker has data that day
    weighted_vals = np.where(mask_valid, group_returns * group_weights[:, None], 0.0)
    numerator = weighted_vals.sum(axis=0)   # length n_days

    # per-day denom: sum of abs(weights) for tickers present that day
    denom_gross_per_day = (mask_valid * np.abs(group_weights)[:, None]).sum(axis=0)  # length n_days

    # build gross-normalized portfolio curve (per day)
    pg = np.full(n_days, np.nan)
    ok = denom_gross_per_day != 0
    pg[ok] = numerator[ok] / denom_gross_per_day[ok]

    # net-normalized (divide by sum of signed weights) if sum != 0
    denom_net = group_weights.sum()
    pn = None
    if denom_net != 0:
        pn = numerator / denom_net   # note: if some tickers missing on a day, denominator is constant net weight but numerator uses available tickers

    portfolio_gross[pd.to_datetime(trade_date)] = pg
    if pn is not None:
        portfolio_net[pd.to_datetime(trade_date)] = pn

# ---------- DataFrames (index = day offsets) ----------
portfolio_gross_df = pd.DataFrame(portfolio_gross, index=day_idx).sort_index(axis=1)
portfolio_net_df   = pd.DataFrame(portfolio_net, index=day_idx) if portfolio_net else None

if portfolio_gross_df.empty:
    raise ValueError("No portfolio curves were produced (empty result). Check your file and that trade dates / price columns are correct.")

# ---------- average curves ----------
avg_gross = portfolio_gross_df.mean(axis=1, skipna=True)
avg_net = portfolio_net_df.mean(axis=1, skipna=True) if (portfolio_net_df is not None and not portfolio_net_df.empty) else None

# ---------- plotting (daily x-axis) ----------
plt.figure(figsize=(13,8))

# plot each trade-date curve (light)
max_legend = 30  # to avoid overly large legends; show at most this many in legend
legend_labels = []
for i, col in enumerate(portfolio_gross_df.columns):
    y = portfolio_gross_df[col].values
    plt.plot(day_idx, y, alpha=0.25, linewidth=1, color='gray')
    if i < max_legend:
        legend_labels.append(str(col.date()))
# overlay average gross-normalized (bold)
plt.plot(day_idx, avg_gross.values, color='black', linewidth=2.5, label='Avg (gross-normalized)')
# overlay avg net if available
if avg_net is not None:
    plt.plot(day_idx, avg_net.values, color='red', linewidth=1.5, linestyle='--', label='Avg (net-normalized)')

plt.axhline(0, color='black', linestyle='--', linewidth=0.8)
plt.xlabel('Days since trade date (t0)')
plt.ylabel('Return (vs t0)')
plt.title('Portfolio returns by trade date (each line = trades executed that date)')
plt.grid(True)

# build legend: show only the average + up to N trade-dates to avoid clutter
handles, labels = plt.gca().get_legend_handles_labels()
# manually add a sample of trade dates (optional)
if len(portfolio_gross_df.columns) <= max_legend:
    # show all trade-date names in legend (may be many)
    plt.legend()
else:
    # show only avg lines in legend + note
    plt.legend(handles=handles, labels=labels)
    plt.text(0.99, 0.02, f"Plotted {len(portfolio_gross_df.columns)} trade dates; individual dates shown as faint gray lines.",
             transform=plt.gca().transAxes, ha='right', va='bottom', fontsize=9, alpha=0.8)

plt.show()

# ---------- optional: save portfolio curves to CSV ----------
portfolio_gross_df.to_csv("portfolio_curves_gross_by_trade_date.csv", index_label="day_offset")
if portfolio_net_df is not None:
    portfolio_net_df.to_csv("portfolio_curves_net_by_trade_date.csv", index_label="day_offset")

print("Done. Saved portfolio_curves_gross_by_trade_date.csv (and net file if applicable).")


